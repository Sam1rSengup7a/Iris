{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd85b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5d1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and preprocess it\n",
    "df = pd.read_csv('NSE-TATAGLOBAL.csv', parse_dates=['Date'], index_col='Date')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07653e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a stacked LSTM model\n",
    "def create_model(units, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(None, n_features)))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757306ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_size = int(len(df_scaled) * 0.8)\n",
    "train_data = df_scaled[:train_size, :]\n",
    "test_data = df_scaled[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca1e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and labels for the training data\n",
    "n_steps = 60\n",
    "x_train, y_train = [], []\n",
    "for i in range(n_steps, len(train_data)):\n",
    "    x_train.append(train_data[i - n_steps:i, :])\n",
    "    y_train.append(train_data[i, 0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c04200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and labels for the testing data\n",
    "x_test, y_test = [], []\n",
    "for i in range(n_steps, len(test_data)):\n",
    "    x_test.append(test_data[i - n_steps:i, :])\n",
    "    y_test.append(test_data[i, 0])\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88911ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 [==============================] - 7s 33ms/step - loss: 0.0092\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.0012\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.0010\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 9.3007e-04\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 9.4340e-04\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 8.8985e-04\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 8.0956e-04\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 8.1752e-04\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 6.9021e-04\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 6.5729e-04\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 6.5855e-04\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 6.5688e-04\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 5.7452e-04\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 5.3931e-04\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 5.2540e-04\n",
      "Epoch 16/50\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 5.5605e-04\n",
      "Epoch 17/50\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 5.0234e-04\n",
      "Epoch 18/50\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 4.9913e-04\n",
      "Epoch 19/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 4.5747e-04\n",
      "Epoch 20/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 4.2333e-04\n",
      "Epoch 21/50\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 4.1154e-04\n",
      "Epoch 22/50\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 4.1390e-04\n",
      "Epoch 23/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 4.5881e-04\n",
      "Epoch 24/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 4.4154e-04\n",
      "Epoch 25/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 4.2706e-04\n",
      "Epoch 26/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.9830e-04\n",
      "Epoch 27/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 3.7400e-04\n",
      "Epoch 28/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 3.6876e-04\n",
      "Epoch 29/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 3.5439e-04\n",
      "Epoch 30/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 3.5557e-04\n",
      "Epoch 31/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 3.4883e-04\n",
      "Epoch 32/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.5300e-04\n",
      "Epoch 33/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.0431e-04\n",
      "Epoch 34/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.6323e-04\n",
      "Epoch 35/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.0475e-04\n",
      "Epoch 36/50\n",
      "49/49 [==============================] - 1s 31ms/step - loss: 3.0256e-04\n",
      "Epoch 37/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.0736e-04\n",
      "Epoch 38/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.0398e-04\n",
      "Epoch 39/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.3970e-04\n",
      "Epoch 40/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.9501e-04\n",
      "Epoch 41/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.0437e-04\n",
      "Epoch 42/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.7135e-04\n",
      "Epoch 43/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.7799e-04\n",
      "Epoch 44/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.6984e-04\n",
      "Epoch 45/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.7284e-04\n",
      "Epoch 46/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.9190e-04\n",
      "Epoch 47/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 3.2529e-04\n",
      "Epoch 48/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.6107e-04\n",
      "Epoch 49/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.7359e-04\n",
      "Epoch 50/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 2.9329e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5867020a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model and fit it to the training data\n",
    "model = create_model(50, df_scaled.shape[1])\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8d7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 14ms/step - loss: 1.4466e-04\n",
      "Mean Squared Error: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model on the testing data\n",
    "mse = model.evaluate(x_test, y_test)\n",
    "print(\"Mean Squared Error: {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f54cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data using the trained model\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632109aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scale the predictions and actual values\n",
    "y_pred = scaler.inverse_transform(np.concatenate((y_pred, x_test[:, -1, 1:]), axis=1))[:, 0]\n",
    "y_test = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), x_test[:, -1, 1:]), axis=1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e27974d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Predicted Close  Actual Close\n",
      "0   2011-12-09        90.171064         88.75\n",
      "1   2011-12-08        90.543982         90.85\n",
      "2   2011-12-07        91.052089         91.00\n",
      "3   2011-12-05        91.624300         91.70\n",
      "4   2011-12-02        92.199573         88.60\n",
      "..         ...              ...           ...\n",
      "342 2010-07-27       116.884757        117.60\n",
      "343 2010-07-26       117.837014        120.10\n",
      "344 2010-07-23       118.927651        121.80\n",
      "345 2010-07-22       120.459073        120.30\n",
      "346 2010-07-21       121.092256        122.10\n",
      "\n",
      "[347 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted and actual values\n",
    "predictions = pd.DataFrame({'Date': df.index[train_size + n_steps:], 'Predicted Close': y_pred, 'Actual Close': y_test})\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
